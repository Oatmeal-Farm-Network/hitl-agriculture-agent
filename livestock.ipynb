{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agriculture RAG Chatbot - Backend Logic\n",
    "\n",
    "This notebook contains the complete backend logic for the Livestock Advisor chatbot.\n",
    "\n",
    "**Components:**\n",
    "1. Configuration Settings\n",
    "2. Database Operations (SQL Server)\n",
    "3. RAG System (Firestore + Vector Search)\n",
    "4. LangGraph Agent (Query Classification & Response Generation)\n",
    "5. Chat Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if dependencies are not installed\n",
    "# !pip install python-dotenv pymssql pandas google-cloud-firestore langchain-google-vertexai langchain-google-genai langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config] Using Vertex AI (Project: animated-flare-421518, Location: us-central1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Database Configuration\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\", \"\").strip(),\n",
    "    \"port\": int(os.getenv(\"DB_PORT\", \"1433\").strip()),\n",
    "    \"user\": os.getenv(\"DB_USER\", \"\").strip(),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\", \"\"),\n",
    "    \"database\": os.getenv(\"DB_NAME\", \"\").strip(),\n",
    "}\n",
    "\n",
    "# Allowed tables for security\n",
    "ALLOWED_TABLES = [\n",
    "    \"Speciesavailable\",\n",
    "    \"Speciesbreedlookuptable\",\n",
    "    \"Speciescategory\",\n",
    "    \"Speciescolorlookuptable\",\n",
    "    \"Speciespatternlookuptable\",\n",
    "    \"Speciesregistrationtypelookuptable\",\n",
    "]\n",
    "\n",
    "# GCP Configuration\n",
    "GCP_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\", \"\").strip()\n",
    "GCP_LOCATION = os.getenv(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\").strip()\n",
    "GCP_CREDENTIALS = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\", \"\").strip()\n",
    "\n",
    "# Determine if using Vertex AI\n",
    "USE_VERTEX_AI = bool(GCP_PROJECT)\n",
    "\n",
    "# LLM Configuration\n",
    "if USE_VERTEX_AI:\n",
    "    LLM_MODEL = os.getenv(\"VERTEX_AI_MODEL\", \"gemini-2.0-flash-001\")\n",
    "else:\n",
    "    LLM_MODEL = os.getenv(\"GEMINI_MODEL\", \"gemini-2.0-flash\")\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"\").strip()\n",
    "\n",
    "# RAG Configuration\n",
    "EMBEDDING_MODEL = \"text-embedding-004\"\n",
    "EMBEDDING_DIMENSIONS = 768\n",
    "TOP_K_RESULTS = 10\n",
    "\n",
    "# Firestore Configuration\n",
    "FIRESTORE_DATABASE = os.getenv(\"FIRESTORE_DATABASE\", \"(default)\").strip()\n",
    "FIRESTORE_COLLECTION = \"livestock_knowledge\"\n",
    "\n",
    "# Print configuration\n",
    "if USE_VERTEX_AI:\n",
    "    print(f\"[Config] Using Vertex AI (Project: {GCP_PROJECT}, Location: {GCP_LOCATION})\")\n",
    "else:\n",
    "    print(\"[Config] Using Google AI API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials path: credentials\\animated-flare-421518-8be5041fab40.json\n",
      "File exists: True\n",
      "Service account email: vertex-express@animated-flare-421518.iam.gserviceaccount.com\n",
      "Project ID: animated-flare-421518\n",
      "[RAG] ✓ Firestore write/delete test passed\n"
     ]
    }
   ],
   "source": [
    "# Add this diagnostic code to check credentials\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "cred_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "if cred_path:\n",
    "    print(f\"Credentials path: {cred_path}\")\n",
    "    print(f\"File exists: {os.path.exists(cred_path)}\")\n",
    "    try:\n",
    "        creds = service_account.Credentials.from_service_account_file(cred_path)\n",
    "        print(f\"Service account email: {creds.service_account_email}\")\n",
    "        print(f\"Project ID: {creds.project_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading credentials: {e}\")\n",
    "else:\n",
    "    print(\"GOOGLE_APPLICATION_CREDENTIALS not set\")\n",
    "\n",
    "# Add this test cell to verify Firestore access\n",
    "try:\n",
    "    # Test basic Firestore access\n",
    "    test_collection = rag.firestore_db.collection(\"_test\")\n",
    "    test_doc = test_collection.document(\"test\")\n",
    "    test_doc.set({\"test\": \"value\"})\n",
    "    test_doc.delete()\n",
    "    print(\"[RAG] ✓ Firestore write/delete test passed\")\n",
    "except Exception as e:\n",
    "    print(f\"[RAG] ✗ Firestore access test failed: {e}\")\n",
    "    print(f\"[RAG] Error type: {type(e).__name__}\")\n",
    "    print(f\"[RAG] This usually means:\")\n",
    "    print(f\"  1. Service account lacks Firestore permissions\")\n",
    "    print(f\"  2. Firestore database doesn't exist\")\n",
    "    print(f\"  3. Firestore API is not enabled for the project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Database Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB] Database class initialized\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "\n",
    "class Database:\n",
    "    \"\"\"Manages database connections and queries.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._connection = None\n",
    "        self._allowed_tables = [t.lower() for t in ALLOWED_TABLES]\n",
    "\n",
    "    @property\n",
    "    def connection(self):\n",
    "        \"\"\"Lazy connection to database.\"\"\"\n",
    "        if self._connection is None:\n",
    "            try:\n",
    "                self._connection = pymssql.connect(\n",
    "                    server=DB_CONFIG[\"host\"],\n",
    "                    port=DB_CONFIG[\"port\"],\n",
    "                    user=DB_CONFIG[\"user\"],\n",
    "                    password=DB_CONFIG[\"password\"],\n",
    "                    database=DB_CONFIG[\"database\"],\n",
    "                    as_dict=True\n",
    "                )\n",
    "                print(f\"[DB] Connected to {DB_CONFIG['database']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[DB] Connection failed: {e}\")\n",
    "                raise\n",
    "        return self._connection\n",
    "\n",
    "    def _validate_query(self, query: str) -> None:\n",
    "        \"\"\"Validate query only accesses allowed tables.\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        tables = re.findall(r'from\\s+\\[?(\\w+)\\]?', query_lower)\n",
    "        tables += re.findall(r'join\\s+\\[?(\\w+)\\]?', query_lower)\n",
    "\n",
    "        for table in tables:\n",
    "            if table not in self._allowed_tables:\n",
    "                raise PermissionError(f\"Access denied to table: {table}\")\n",
    "\n",
    "    def execute(self, query: str) -> pd.DataFrame:\n",
    "        \"\"\"Execute a SELECT query and return results as DataFrame.\"\"\"\n",
    "        self._validate_query(query)\n",
    "\n",
    "        cursor = self.connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "        return pd.DataFrame(results) if results else pd.DataFrame()\n",
    "\n",
    "    def get_schema(self) -> str:\n",
    "        \"\"\"Get schema for all allowed tables.\"\"\"\n",
    "        schema_parts = []\n",
    "        cursor = self.connection.cursor()\n",
    "\n",
    "        for table in ALLOWED_TABLES:\n",
    "            cursor.execute(f\"\"\"\n",
    "                SELECT COLUMN_NAME, DATA_TYPE\n",
    "                FROM INFORMATION_SCHEMA.COLUMNS\n",
    "                WHERE TABLE_NAME = '{table}'\n",
    "            \"\"\")\n",
    "            cols = cursor.fetchall()\n",
    "            if cols:\n",
    "                schema_parts.append(f\"-- {table}\")\n",
    "                for col in cols:\n",
    "                    schema_parts.append(f\"   {col['COLUMN_NAME']} ({col['DATA_TYPE']})\")\n",
    "\n",
    "        return \"\\n\".join(schema_parts)\n",
    "\n",
    "    def get_all_species(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get all species with their details.\"\"\"\n",
    "        df = self.execute(\"\"\"\n",
    "            SELECT SpeciesID, Species, MaleTerm, FemaleTerm, BabyTerm,\n",
    "                   SingularTerm, PluralTerm, GestationPeriod\n",
    "            FROM Speciesavailable\n",
    "            WHERE SpeciesAvailable = 1\n",
    "        \"\"\")\n",
    "        return df.to_dict('records') if not df.empty else []\n",
    "\n",
    "    def get_breeds_for_species(self, species_id: int) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get all breeds for a specific species.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT b.BreedLookupID, b.Breed, b.Breeddescription,\n",
    "                   b.MeatBreed, b.MilkBreed, b.WoolBreed, b.EggBreed, b.Working,\n",
    "                   s.Species\n",
    "            FROM Speciesbreedlookuptable b\n",
    "            JOIN Speciesavailable s ON b.SpeciesID = s.SpeciesID\n",
    "            WHERE b.SpeciesID = {species_id} AND b.breedavailable = 1\n",
    "        \"\"\")\n",
    "        return df.to_dict('records') if not df.empty else []\n",
    "\n",
    "    def get_all_breeds(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get all breeds with species info.\"\"\"\n",
    "        df = self.execute(\"\"\"\n",
    "            SELECT TOP 2000 b.BreedLookupID, b.Breed, b.Breeddescription,\n",
    "                   b.MeatBreed, b.MilkBreed, b.WoolBreed, b.EggBreed, b.Working,\n",
    "                   s.Species, s.SpeciesID\n",
    "            FROM Speciesbreedlookuptable b\n",
    "            JOIN Speciesavailable s ON b.SpeciesID = s.SpeciesID\n",
    "            WHERE b.breedavailable = 1\n",
    "        \"\"\")\n",
    "        return df.to_dict('records') if not df.empty else []\n",
    "\n",
    "    def get_colors_for_species(self, species_id: int) -> List[str]:\n",
    "        \"\"\"Get available colors for a species.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT DISTINCT SpeciesColor\n",
    "            FROM Speciescolorlookuptable\n",
    "            WHERE SpeciesID = {species_id}\n",
    "        \"\"\")\n",
    "        return df['SpeciesColor'].tolist() if not df.empty else []\n",
    "\n",
    "    def get_patterns_for_species(self, species_id: int) -> List[str]:\n",
    "        \"\"\"Get available patterns for a species.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT DISTINCT SpeciesColor as Pattern\n",
    "            FROM Speciespatternlookuptable\n",
    "            WHERE SpeciesID = {species_id}\n",
    "        \"\"\")\n",
    "        return df['Pattern'].tolist() if not df.empty else []\n",
    "\n",
    "    def get_categories_for_species(self, species_id: int) -> List[str]:\n",
    "        \"\"\"Get categories for a species.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT SpeciesCategory\n",
    "            FROM Speciescategory\n",
    "            WHERE SpeciesID = {species_id}\n",
    "            ORDER BY SpeciesCategoryOrder\n",
    "        \"\"\")\n",
    "        return df['SpeciesCategory'].tolist() if not df.empty else []\n",
    "\n",
    "    def search_breeds(self, search_term: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search breeds by name.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT TOP 20 b.Breed, b.Breeddescription, s.Species,\n",
    "                   b.MeatBreed, b.MilkBreed, b.WoolBreed, b.EggBreed\n",
    "            FROM Speciesbreedlookuptable b\n",
    "            JOIN Speciesavailable s ON b.SpeciesID = s.SpeciesID\n",
    "            WHERE b.Breed LIKE '%{search_term}%' AND b.breedavailable = 1\n",
    "        \"\"\")\n",
    "        return df.to_dict('records') if not df.empty else []\n",
    "\n",
    "    def get_database_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get a summary of database contents.\"\"\"\n",
    "        summary = {}\n",
    "\n",
    "        # Count species\n",
    "        df = self.execute(\"SELECT COUNT(*) as cnt FROM Speciesavailable WHERE SpeciesAvailable = 1\")\n",
    "        summary['total_species'] = df['cnt'].iloc[0] if not df.empty else 0\n",
    "\n",
    "        # Count breeds\n",
    "        df = self.execute(\"SELECT COUNT(*) as cnt FROM Speciesbreedlookuptable WHERE breedavailable = 1\")\n",
    "        summary['total_breeds'] = df['cnt'].iloc[0] if not df.empty else 0\n",
    "\n",
    "        # Count colors\n",
    "        df = self.execute(\"SELECT COUNT(DISTINCT SpeciesColor) as cnt FROM Speciescolorlookuptable\")\n",
    "        summary['total_colors'] = df['cnt'].iloc[0] if not df.empty else 0\n",
    "\n",
    "        # Count patterns\n",
    "        df = self.execute(\"SELECT COUNT(DISTINCT SpeciesColor) as cnt FROM Speciespatternlookuptable\")\n",
    "        summary['total_patterns'] = df['cnt'].iloc[0] if not df.empty else 0\n",
    "\n",
    "        return summary\n",
    "\n",
    "\n",
    "# Create database instance\n",
    "db = Database()\n",
    "print(\"[DB] Database class initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG System (Firestore + Vector Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bring\\AppData\\Local\\Temp\\ipykernel_34624\\4158060170.py:10: DeprecationWarning: Use [`GoogleGenerativeAIEmbeddings`][langchain_google_genai.GoogleGenerativeAIEmbeddings] instead.\n",
      "  embeddings = VertexAIEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAG] Using Vertex AI Embeddings (text-embedding-004)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from google.cloud import firestore\n",
    "from google.cloud.firestore_v1.vector import Vector\n",
    "from google.cloud.firestore_v1.base_vector_query import DistanceMeasure\n",
    "\n",
    "# Initialize embedding model based on configuration\n",
    "if USE_VERTEX_AI:\n",
    "    from langchain_google_vertexai import VertexAIEmbeddings\n",
    "    embeddings = VertexAIEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL,\n",
    "        project=GCP_PROJECT,\n",
    "        location=GCP_LOCATION\n",
    "    )\n",
    "    print(f\"[RAG] Using Vertex AI Embeddings ({EMBEDDING_MODEL})\")\n",
    "else:\n",
    "    from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=f\"models/{EMBEDDING_MODEL}\",\n",
    "        google_api_key=GOOGLE_API_KEY\n",
    "    )\n",
    "    print(f\"[RAG] Using Google AI Embeddings ({EMBEDDING_MODEL})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAG] RAG System class initialized\n"
     ]
    }
   ],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"RAG system using Firestore Vector Search.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._db = None\n",
    "        self._initialized = False\n",
    "\n",
    "\n",
    "    @property\n",
    "    def firestore_db(self):\n",
    "        \"\"\"Lazy initialization of Firestore client.\"\"\"\n",
    "        if self._db is None:\n",
    "            # Load credentials if service account file is provided\n",
    "            credentials = None\n",
    "            if GCP_CREDENTIALS:\n",
    "                try:\n",
    "                    from google.oauth2 import service_account\n",
    "                    credentials = service_account.Credentials.from_service_account_file(\n",
    "                        GCP_CREDENTIALS,\n",
    "                        scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "                    )\n",
    "                    print(f\"[RAG] Loaded credentials from {GCP_CREDENTIALS}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[RAG] Warning: Could not load credentials from {GCP_CREDENTIALS}: {e}\")\n",
    "                    print(\"[RAG] Falling back to Application Default Credentials\")\n",
    "            \n",
    "            # Initialize Firestore client with credentials if available\n",
    "            if credentials:\n",
    "                self._db = firestore.Client(\n",
    "                    project=GCP_PROJECT,\n",
    "                    database=FIRESTORE_DATABASE,\n",
    "                    credentials=credentials\n",
    "                )\n",
    "                print(f\"[RAG] Firestore client initialized with explicit credentials\")\n",
    "            else:\n",
    "                self._db = firestore.Client(\n",
    "                    project=GCP_PROJECT,\n",
    "                    database=FIRESTORE_DATABASE\n",
    "                )\n",
    "                print(f\"[RAG] Firestore client initialized with Application Default Credentials\")\n",
    "            print(f\"[RAG] Connected to Firestore (Project: {GCP_PROJECT}, Database: {FIRESTORE_DATABASE})\")\n",
    "        return self._db\n",
    "\n",
    "    @property\n",
    "    def collection(self):\n",
    "        \"\"\"Get the Firestore collection.\"\"\"\n",
    "        return self.firestore_db.collection(FIRESTORE_COLLECTION)\n",
    "\n",
    "    def _get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embedding for text.\"\"\"\n",
    "        return embeddings.embed_query(text)\n",
    "\n",
    "    def _get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Generate embeddings for multiple texts.\"\"\"\n",
    "        return embeddings.embed_documents(texts)\n",
    "\n",
    "    def _format_breed_document(self, breed: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format breed data into a searchable document.\"\"\"\n",
    "        parts = [f\"Breed: {breed.get('Breed', 'Unknown')}\"]\n",
    "\n",
    "        if breed.get('Species'):\n",
    "            parts.append(f\"Species: {breed['Species']}\")\n",
    "\n",
    "        if breed.get('Breeddescription'):\n",
    "            parts.append(f\"Description: {breed['Breeddescription']}\")\n",
    "\n",
    "        purposes = []\n",
    "        if breed.get('MeatBreed'):\n",
    "            purposes.append(\"meat production\")\n",
    "        if breed.get('MilkBreed'):\n",
    "            purposes.append(\"milk/dairy production\")\n",
    "        if breed.get('WoolBreed'):\n",
    "            purposes.append(\"wool/fiber production\")\n",
    "        if breed.get('EggBreed'):\n",
    "            purposes.append(\"egg production\")\n",
    "        if breed.get('Working'):\n",
    "            purposes.append(\"working/draft animal\")\n",
    "\n",
    "        if purposes:\n",
    "            parts.append(f\"Purpose: {', '.join(purposes)}\")\n",
    "\n",
    "        return \" | \".join(parts)\n",
    "\n",
    "    def _format_species_document(self, species: Dict[str, Any], colors: List[str],\n",
    "                                  patterns: List[str], categories: List[str]) -> str:\n",
    "        \"\"\"Format species data into a searchable document.\"\"\"\n",
    "        parts = [f\"Species: {species.get('Species', 'Unknown')}\"]\n",
    "\n",
    "        if species.get('SingularTerm'):\n",
    "            parts.append(f\"Singular: {species['SingularTerm']}\")\n",
    "        if species.get('PluralTerm'):\n",
    "            parts.append(f\"Plural: {species['PluralTerm']}\")\n",
    "        if species.get('MaleTerm'):\n",
    "            parts.append(f\"Male term: {species['MaleTerm']}\")\n",
    "        if species.get('FemaleTerm'):\n",
    "            parts.append(f\"Female term: {species['FemaleTerm']}\")\n",
    "        if species.get('BabyTerm'):\n",
    "            parts.append(f\"Baby term: {species['BabyTerm']}\")\n",
    "        if species.get('GestationPeriod'):\n",
    "            parts.append(f\"Gestation period: {species['GestationPeriod']} days\")\n",
    "\n",
    "        if colors:\n",
    "            parts.append(f\"Available colors: {', '.join(colors[:20])}\")\n",
    "        if patterns:\n",
    "            parts.append(f\"Available patterns: {', '.join(patterns[:20])}\")\n",
    "        if categories:\n",
    "            parts.append(f\"Categories: {', '.join(categories[:15])}\")\n",
    "\n",
    "        return \" | \".join(parts)\n",
    "\n",
    "    def _check_if_indexed(self) -> bool:\n",
    "        \"\"\"Check if data is already indexed in Firestore.\"\"\"\n",
    "        docs = self.collection.limit(1).get()\n",
    "        return len(list(docs)) > 0\n",
    "\n",
    "    def _get_document_count(self) -> int:\n",
    "        \"\"\"Get the count of documents in the collection using aggregation.\"\"\"\n",
    "        try:\n",
    "            count_query = self.collection.count()\n",
    "            result = count_query.get()\n",
    "            return result[0][0].value\n",
    "        except Exception as e:\n",
    "            print(f\"[RAG] Warning: Could not get document count: {e}\")\n",
    "            return -1\n",
    "\n",
    "    def index_database(self, force_rebuild: bool = False) -> int:\n",
    "        \"\"\"Index all livestock data to Firestore with embeddings.\"\"\"\n",
    "        # Check if already indexed\n",
    "        if not force_rebuild and self._check_if_indexed():\n",
    "            count = self._get_document_count()\n",
    "            if count >= 0:\n",
    "                print(f\"[RAG] Using existing Firestore index ({count} documents)\")\n",
    "            else:\n",
    "                print(\"[RAG] Using existing Firestore index\")\n",
    "            self._initialized = True\n",
    "            return max(count, 0)\n",
    "\n",
    "        print(\"[RAG] Building Firestore vector index from database...\")\n",
    "\n",
    "        # Clear existing documents if rebuilding\n",
    "        if force_rebuild:\n",
    "            print(\"[RAG] Clearing existing documents...\")\n",
    "            deleted_count = 0\n",
    "            while True:\n",
    "                docs = list(self.collection.limit(100).stream())\n",
    "                if not docs:\n",
    "                    break\n",
    "                batch = self.firestore_db.batch()\n",
    "                for doc in docs:\n",
    "                    batch.delete(doc.reference)\n",
    "                batch.commit()\n",
    "                deleted_count += len(docs)\n",
    "                print(f\"[RAG] Deleted {deleted_count} documents...\")\n",
    "\n",
    "        documents = []\n",
    "\n",
    "        # Prepare breed documents\n",
    "        print(\"[RAG] Preparing breed documents...\")\n",
    "        breeds = db.get_all_breeds()\n",
    "        for breed in breeds:\n",
    "            content = self._format_breed_document(breed)\n",
    "            documents.append({\n",
    "                \"id\": f\"breed_{breed.get('BreedLookupID', '')}\",\n",
    "                \"content\": content,\n",
    "                \"type\": \"breed\",\n",
    "                \"breed_name\": breed.get('Breed', ''),\n",
    "                \"species\": breed.get('Species', ''),\n",
    "                \"species_id\": str(breed.get('SpeciesID', ''))\n",
    "            })\n",
    "\n",
    "        # Prepare species documents\n",
    "        print(\"[RAG] Preparing species documents...\")\n",
    "        species_list = db.get_all_species()\n",
    "        for species in species_list:\n",
    "            species_id = species.get('SpeciesID')\n",
    "            colors = db.get_colors_for_species(species_id)\n",
    "            patterns = db.get_patterns_for_species(species_id)\n",
    "            categories = db.get_categories_for_species(species_id)\n",
    "\n",
    "            content = self._format_species_document(species, colors, patterns, categories)\n",
    "            documents.append({\n",
    "                \"id\": f\"species_{species_id}\",\n",
    "                \"content\": content,\n",
    "                \"type\": \"species\",\n",
    "                \"species_name\": species.get('Species', ''),\n",
    "                \"species_id\": str(species_id)\n",
    "            })\n",
    "\n",
    "        if not documents:\n",
    "            print(\"[RAG] No documents to index\")\n",
    "            return 0\n",
    "\n",
    "        # Generate embeddings in batches and store in Firestore\n",
    "        print(f\"[RAG] Generating embeddings for {len(documents)} documents...\")\n",
    "\n",
    "        batch_size = 20\n",
    "        total_indexed = 0\n",
    "\n",
    "        for i in range(0, len(documents), batch_size):\n",
    "            batch_docs = documents[i:i+batch_size]\n",
    "            contents = [doc[\"content\"] for doc in batch_docs]\n",
    "\n",
    "            # Generate embeddings\n",
    "            batch_embeddings = self._get_embeddings_batch(contents)\n",
    "\n",
    "            # Store in Firestore with embeddings\n",
    "            batch = self.firestore_db.batch()\n",
    "            for doc, embedding in zip(batch_docs, batch_embeddings):\n",
    "                doc_ref = self.collection.document(doc[\"id\"])\n",
    "                batch.set(doc_ref, {\n",
    "                    \"content\": doc[\"content\"],\n",
    "                    \"type\": doc[\"type\"],\n",
    "                    \"metadata\": {k: v for k, v in doc.items() if k not in [\"id\", \"content\", \"type\"]},\n",
    "                    \"embedding\": Vector(embedding)\n",
    "                })\n",
    "\n",
    "            batch.commit()\n",
    "            total_indexed += len(batch_docs)\n",
    "            print(f\"[RAG] Indexed {total_indexed}/{len(documents)}\")\n",
    "\n",
    "        self._initialized = True\n",
    "        print(f\"[RAG] Index complete: {total_indexed} documents in Firestore\")\n",
    "        return total_indexed\n",
    "\n",
    "    def search(self, query: str, n_results: int = TOP_K_RESULTS,\n",
    "               filter_type: Optional[str] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for relevant documents using vector similarity.\"\"\"\n",
    "        if not self._initialized and not self._check_if_indexed():\n",
    "            self.index_database()\n",
    "            self._initialized = True\n",
    "\n",
    "        # Generate query embedding\n",
    "        query_embedding = self._get_embedding(query)\n",
    "\n",
    "        # Perform vector search\n",
    "        collection_ref = self.collection\n",
    "\n",
    "        # Apply type filter if specified\n",
    "        if filter_type:\n",
    "            collection_ref = collection_ref.where(\"type\", \"==\", filter_type)\n",
    "\n",
    "        # Vector nearest neighbor search\n",
    "        vector_query = collection_ref.find_nearest(\n",
    "            vector_field=\"embedding\",\n",
    "            query_vector=Vector(query_embedding),\n",
    "            distance_measure=DistanceMeasure.COSINE,\n",
    "            limit=n_results\n",
    "        )\n",
    "\n",
    "        results = vector_query.get()\n",
    "\n",
    "        # Format results\n",
    "        formatted = []\n",
    "        for doc in results:\n",
    "            data = doc.to_dict()\n",
    "            formatted.append({\n",
    "                \"content\": data.get(\"content\", \"\"),\n",
    "                \"metadata\": data.get(\"metadata\", {}),\n",
    "                \"type\": data.get(\"type\", \"unknown\"),\n",
    "                \"relevance_score\": 1.0\n",
    "            })\n",
    "\n",
    "        return formatted\n",
    "\n",
    "    def get_context_for_query(self, query: str) -> str:\n",
    "        \"\"\"Get formatted context string for LLM.\"\"\"\n",
    "        results = self.search(query)\n",
    "\n",
    "        if not results:\n",
    "            return \"No relevant information found in the database.\"\n",
    "\n",
    "        context_parts = [\"Relevant information from the livestock database:\\n\"]\n",
    "        for i, result in enumerate(results, 1):\n",
    "            context_parts.append(f\"{i}. {result['content']}\")\n",
    "            context_parts.append(f\"   (Type: {result['type']})\")\n",
    "            context_parts.append(\"\")\n",
    "\n",
    "        return \"\\n\".join(context_parts)\n",
    "\n",
    "\n",
    "# Create RAG instance\n",
    "rag = RAGSystem()\n",
    "print(\"[RAG] RAG System class initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangGraph Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Using Vertex AI LLM (gemini-2.0-flash-001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bring\\AppData\\Local\\Temp\\ipykernel_34624\\1243483521.py:8: DeprecationWarning: Use [`ChatGoogleGenerativeAI`][langchain_google_genai.ChatGoogleGenerativeAI] instead.\n",
      "  llm = ChatVertexAI(\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Initialize LLM based on configuration\n",
    "if USE_VERTEX_AI:\n",
    "    from langchain_google_vertexai import ChatVertexAI\n",
    "    llm = ChatVertexAI(\n",
    "        model=LLM_MODEL,\n",
    "        project=GCP_PROJECT,\n",
    "        location=GCP_LOCATION,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    print(f\"[Agent] Using Vertex AI LLM ({LLM_MODEL})\")\n",
    "else:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=LLM_MODEL,\n",
    "        temperature=0.3,\n",
    "        google_api_key=GOOGLE_API_KEY\n",
    "    )\n",
    "    print(f\"[Agent] Using Google AI LLM ({LLM_MODEL})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict, total=False):\n",
    "    \"\"\"State for the chat agent.\"\"\"\n",
    "    messages: List[dict]\n",
    "    user_input: str\n",
    "    context: str\n",
    "    response: str\n",
    "    query_type: str  # \"livestock\" or \"general\"\n",
    "\n",
    "\n",
    "# Classification prompt\n",
    "CLASSIFICATION_PROMPT = \"\"\"Classify if the following user question is related to livestock, agriculture, animal breeds, or farming.\n",
    "\n",
    "Livestock-related topics include:\n",
    "- Animal breeds (cattle, sheep, goats, pigs, poultry, horses, etc.)\n",
    "- Species information, characteristics, terminology\n",
    "- Colors, patterns, categories of animals\n",
    "- Farming, breeding, animal husbandry\n",
    "- Agricultural practices related to animals\n",
    "\n",
    "Respond with ONLY one word: \"livestock\" if related, or \"general\" if not related.\n",
    "\n",
    "User question: {question}\n",
    "\n",
    "Classification:\"\"\"\n",
    "\n",
    "\n",
    "# System prompt for livestock queries\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert livestock advisor with access to a comprehensive database of animal breeds, species, colors, patterns, and categories.\n",
    "\n",
    "Your knowledge includes:\n",
    "- Detailed information about various livestock species (cattle, sheep, goats, pigs, poultry, horses, etc.)\n",
    "- Breed characteristics, purposes (meat, milk, wool, eggs, working), and descriptions\n",
    "- Available colors and patterns for each species\n",
    "- Terminology (male/female terms, baby terms, etc.)\n",
    "\n",
    "Guidelines:\n",
    "1. Use the provided context from the database to answer questions accurately\n",
    "2. Be helpful and informative about livestock breeds and species\n",
    "3. If asked about something not in the context, say so honestly\n",
    "4. Format responses clearly with bullet points or numbered lists when appropriate\n",
    "5. Be conversational but professional\n",
    "\n",
    "If the user asks about:\n",
    "- Breeds: Provide breed names, species, purpose, and descriptions\n",
    "- Species: Provide terminology, characteristics, and available breeds\n",
    "- Colors/Patterns: List available options for the species\n",
    "- General questions: Use your knowledge plus the database context\n",
    "\"\"\"\n",
    "\n",
    "# General assistant prompt (for non-livestock questions)\n",
    "GENERAL_PROMPT = \"\"\"You are a helpful, friendly assistant. Answer the user's question to the best of your ability.\n",
    "Be conversational but concise. If you don't know something, say so honestly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_query(state: ChatState) -> ChatState:\n",
    "    \"\"\"Classify if the query is livestock-related or general.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "\n",
    "    if not user_input:\n",
    "        return {\"query_type\": \"general\"}\n",
    "\n",
    "    prompt = CLASSIFICATION_PROMPT.format(question=user_input)\n",
    "    response = llm.invoke(prompt)\n",
    "    classification = response.content.strip().lower()\n",
    "\n",
    "    # Default to livestock if classification is unclear\n",
    "    if \"livestock\" in classification:\n",
    "        query_type = \"livestock\"\n",
    "    else:\n",
    "        query_type = \"general\"\n",
    "\n",
    "    print(f\"[Agent] Query classified as: {query_type}\")\n",
    "    return {\"query_type\": query_type}\n",
    "\n",
    "\n",
    "def route_query(state: ChatState) -> str:\n",
    "    \"\"\"Route to RAG or direct response based on classification.\"\"\"\n",
    "    query_type = state.get(\"query_type\", \"general\")\n",
    "    if query_type == \"livestock\":\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        return \"generate_direct\"\n",
    "\n",
    "\n",
    "def retrieve_context(state: ChatState) -> ChatState:\n",
    "    \"\"\"Retrieve relevant context from RAG system.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "\n",
    "    if not user_input:\n",
    "        return {\"context\": \"\"}\n",
    "\n",
    "    context = rag.get_context_for_query(user_input)\n",
    "    return {\"context\": context}\n",
    "\n",
    "\n",
    "def generate_response(state: ChatState) -> ChatState:\n",
    "    \"\"\"Generate response using LLM with RAG context.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    context = state.get(\"context\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt_parts = [SYSTEM_PROMPT]\n",
    "\n",
    "    if context:\n",
    "        prompt_parts.append(f\"\\n--- DATABASE CONTEXT ---\\n{context}\\n--- END CONTEXT ---\\n\")\n",
    "\n",
    "    # Add chat history (last 10 messages)\n",
    "    if messages:\n",
    "        prompt_parts.append(\"\\nRecent conversation:\")\n",
    "        for msg in messages[-10:]:\n",
    "            role = \"User\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
    "            prompt_parts.append(f\"{role}: {msg['content']}\")\n",
    "\n",
    "    prompt_parts.append(f\"\\nUser: {user_input}\\n\\nAssistant:\")\n",
    "\n",
    "    full_prompt = \"\\n\".join(prompt_parts)\n",
    "\n",
    "    # Generate response\n",
    "    response = llm.invoke(full_prompt)\n",
    "    response_text = response.content\n",
    "\n",
    "    # Update messages\n",
    "    new_messages = list(messages)\n",
    "    new_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    new_messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "\n",
    "    return {\n",
    "        \"response\": response_text,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_direct(state: ChatState) -> ChatState:\n",
    "    \"\"\"Generate response using LLM directly without RAG context.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt_parts = [GENERAL_PROMPT]\n",
    "\n",
    "    # Add chat history (last 10 messages)\n",
    "    if messages:\n",
    "        prompt_parts.append(\"\\nRecent conversation:\")\n",
    "        for msg in messages[-10:]:\n",
    "            role = \"User\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
    "            prompt_parts.append(f\"{role}: {msg['content']}\")\n",
    "\n",
    "    prompt_parts.append(f\"\\nUser: {user_input}\\n\\nAssistant:\")\n",
    "\n",
    "    full_prompt = \"\\n\".join(prompt_parts)\n",
    "\n",
    "    # Generate response\n",
    "    response = llm.invoke(full_prompt)\n",
    "    response_text = response.content\n",
    "\n",
    "    # Update messages\n",
    "    new_messages = list(messages)\n",
    "    new_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    new_messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "\n",
    "    return {\n",
    "        \"response\": response_text,\n",
    "        \"messages\": new_messages\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] LangGraph agent built successfully\n"
     ]
    }
   ],
   "source": [
    "def build_graph():\n",
    "    \"\"\"Build the LangGraph workflow with query classification and routing.\"\"\"\n",
    "    builder = StateGraph(ChatState)\n",
    "\n",
    "    # Add nodes\n",
    "    builder.add_node(\"classify\", classify_query)\n",
    "    builder.add_node(\"retrieve\", retrieve_context)\n",
    "    builder.add_node(\"generate\", generate_response)\n",
    "    builder.add_node(\"generate_direct\", generate_direct)\n",
    "\n",
    "    # Add edges with conditional routing\n",
    "    builder.add_edge(START, \"classify\")\n",
    "    builder.add_conditional_edges(\n",
    "        \"classify\",\n",
    "        route_query,\n",
    "        {\n",
    "            \"retrieve\": \"retrieve\",\n",
    "            \"generate_direct\": \"generate_direct\"\n",
    "        }\n",
    "    )\n",
    "    builder.add_edge(\"retrieve\", \"generate\")\n",
    "    builder.add_edge(\"generate\", END)\n",
    "    builder.add_edge(\"generate_direct\", END)\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    return builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# Create the agent graph\n",
    "agent = build_graph()\n",
    "print(\"[Agent] LangGraph agent built successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GRAPH VISUALIZATION\n",
      "============================================================\n",
      "\n",
      "1. ASCII Visualization:\n",
      "------------------------------------------------------------\n",
      "ASCII visualization not available: Install grandalf to draw graphs: `pip install grandalf`.\n",
      "\n",
      "2. Mermaid Diagram:\n",
      "------------------------------------------------------------\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tclassify(classify)\n",
      "\tretrieve(retrieve)\n",
      "\tgenerate(generate)\n",
      "\tgenerate_direct(generate_direct)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> classify;\n",
      "\tclassify -.-> generate_direct;\n",
      "\tclassify -.-> retrieve;\n",
      "\tretrieve --> generate;\n",
      "\tgenerate --> __end__;\n",
      "\tgenerate_direct --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n",
      "\n",
      "(You can copy this Mermaid code and paste it into https://mermaid.live/ to see the visual diagram)\n",
      "\n",
      "3. PNG Image:\n",
      "------------------------------------------------------------\n",
      "Graph saved as 'livestock_graph.png'\n",
      "Image size: 15683 bytes\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Graph Structure:\n",
      "------------------------------------------------------------\n",
      "Nodes: ['__start__', 'classify', 'retrieve', 'generate', 'generate_direct', '__end__']\n",
      "Number of edges: 6\n",
      "First node: __start__\n",
      "Last node: __end__\n"
     ]
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "print(\"=\" * 60)\n",
    "print(\"GRAPH VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Method 1: ASCII Art (simple text visualization)\n",
    "print(\"\\n1. ASCII Visualization:\")\n",
    "print(\"-\" * 60)\n",
    "try:\n",
    "    graph_repr = agent.get_graph()\n",
    "    print(graph_repr.print_ascii())\n",
    "except Exception as e:\n",
    "    print(f\"ASCII visualization not available: {e}\")\n",
    "\n",
    "# Method 2: Mermaid Diagram (for notebooks or markdown)\n",
    "print(\"\\n2. Mermaid Diagram:\")\n",
    "print(\"-\" * 60)\n",
    "try:\n",
    "    graph_repr = agent.get_graph()\n",
    "    mermaid_diagram = graph_repr.draw_mermaid()\n",
    "    print(mermaid_diagram)\n",
    "    print(\"\\n(You can copy this Mermaid code and paste it into https://mermaid.live/ to see the visual diagram)\")\n",
    "except Exception as e:\n",
    "    print(f\"Mermaid visualization not available: {e}\")\n",
    "\n",
    "# Method 3: Save as PNG (optional)\n",
    "print(\"\\n3. PNG Image:\")\n",
    "print(\"-\" * 60)\n",
    "try:\n",
    "    graph_repr = agent.get_graph()\n",
    "    png_bytes = graph_repr.draw_mermaid_png(output_file_path=\"livestock_graph.png\")\n",
    "    print(\"Graph saved as 'livestock_graph.png'\")\n",
    "    print(f\"Image size: {len(png_bytes)} bytes\")\n",
    "    \n",
    "    # Display in notebook if IPython is available\n",
    "    try:\n",
    "        from IPython.display import Image, display\n",
    "        display(Image(png_bytes))\n",
    "    except ImportError:\n",
    "        print(\"(Install IPython to display image in notebook)\")\n",
    "except Exception as e:\n",
    "    print(f\"PNG visualization not available: {e}\")\n",
    "\n",
    "# Method 4: Print graph structure\n",
    "print(\"\\n4. Graph Structure:\")\n",
    "print(\"-\" * 60)\n",
    "graph_repr = agent.get_graph()\n",
    "print(f\"Nodes: {list(graph_repr.nodes.keys())}\")\n",
    "print(f\"Number of edges: {len(graph_repr.edges)}\")\n",
    "print(f\"First node: {graph_repr.first_node().id if graph_repr.first_node() else 'None'}\")\n",
    "print(f\"Last node: {graph_repr.last_node().id if graph_repr.last_node() else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, thread_id: str = \"default\") -> str:\n",
    "    \"\"\"\n",
    "    Send a message to the chatbot and get a response.\n",
    "\n",
    "    Args:\n",
    "        user_input: The user's message\n",
    "        thread_id: Session/thread identifier for conversation memory\n",
    "\n",
    "    Returns:\n",
    "        The agent's response\n",
    "    \"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    # Get current state to preserve message history\n",
    "    current_state = agent.get_state(config)\n",
    "    messages = current_state.values.get(\"messages\", []) if current_state.values else []\n",
    "\n",
    "    # Run the agent\n",
    "    result = agent.invoke(\n",
    "        {\"user_input\": user_input, \"messages\": messages},\n",
    "        config\n",
    "    )\n",
    "\n",
    "    return result.get(\"response\", \"I apologize, but I couldn't generate a response.\")\n",
    "\n",
    "\n",
    "def initialize():\n",
    "    \"\"\"Initialize the RAG system by indexing the database.\"\"\"\n",
    "    print(\"[Agent] Initializing RAG system...\")\n",
    "    count = rag.index_database()\n",
    "    try:\n",
    "        summary = db.get_database_summary()\n",
    "        print(f\"[Agent] Ready! Database: {summary['total_species']} species, {summary['total_breeds']} breeds\")\n",
    "    except Exception:\n",
    "        print(\"[Agent] Ready! (SQL database unavailable)\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service account from credentials: vertex-express@animated-flare-421518.iam.gserviceaccount.com\n",
      "Expected: vertex-express@animated-flare-421518.iam.gserviceaccount.com\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Check the service account email from credentials\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "cred_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "if cred_path:\n",
    "    creds = service_account.Credentials.from_service_account_file(cred_path)\n",
    "    print(f\"Service account from credentials: {creds.service_account_email}\")\n",
    "    print(f\"Expected: vertex-express@animated-flare-421518.iam.gserviceaccount.com\")\n",
    "    print(f\"Match: {creds.service_account_email == 'vertex-express@animated-flare-421518.iam.gserviceaccount.com'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Initializing RAG system...\n",
      "[RAG] Loaded credentials from credentials\\animated-flare-421518-8be5041fab40.json\n",
      "[RAG] Firestore client initialized with explicit credentials\n",
      "[RAG] Connected to Firestore (Project: animated-flare-421518, Database: charlie)\n",
      "[RAG] Using existing Firestore index (2029 documents)\n",
      "[DB] Connection failed: (20009, b'DB-Lib error message 20009, severity 9:\\nUnable to connect: Adaptive Server is unavailable or does not exist (34.70.16.88)\\nNet-Lib error during Unknown error (10060)\\nDB-Lib error message 20009, severity 9:\\nUnable to connect: Adaptive Server is unavailable or does not exist (34.70.16.88)\\nNet-Lib error during Unknown error (10060)\\n')\n",
      "[Agent] Ready! (SQL database unavailable)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2029"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force reinitialize\n",
    "rag._db = None\n",
    "# Then try again\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize & Test the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Initializing RAG system...\n",
      "[RAG] Using existing Firestore index (2029 documents)\n",
      "[DB] Connection failed: (20009, b'DB-Lib error message 20009, severity 9:\\nUnable to connect: Adaptive Server is unavailable or does not exist (34.70.16.88)\\nNet-Lib error during Unknown error (10060)\\nDB-Lib error message 20009, severity 9:\\nUnable to connect: Adaptive Server is unavailable or does not exist (34.70.16.88)\\nNet-Lib error during Unknown error (10060)\\n')\n",
      "[Agent] Ready! (SQL database unavailable)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2029"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the system\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Query classified as: livestock\n",
      "Response:\n",
      "Here are some cattle breeds known for dairy production, according to the database:\n",
      "\n",
      "*   **Holstein Friesian:** Known as the world's highest-producing dairy animals.\n",
      "*   **Dairy Shorthorn:** A breed with roots in Britain, selectively bred for dairy purposes.\n",
      "*   **Sahiwal:** A zebu breed from the Punjab region, known for its calm demeanor and high milk production, especially in hot climates.\n",
      "*   **American Brown Swiss:** Revered for its unrivaled milk production and esteemed status as one of the most efficient milk producers among dairy breeds.\n",
      "*   **Black Pied:** Known for their high milk production and good milk quality.\n",
      "*   **Danish Jersey:** Known for their high quality dairy production and their distinctive appearance.\n",
      "*   **Illawarras:** Produce large quantities of milk with moderate fat and high protein.\n",
      "*   **Butana:** A dairy breed from eastern Africa.\n"
     ]
    }
   ],
   "source": [
    "# Test with a livestock-related question\n",
    "response = chat(\"What cattle breeds are available for dairy production?\")\n",
    "print(\"Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Query classified as: general\n",
      "Response:\n",
      "I am sorry, I do not have access to real-time information, including weather. To find out the weather, please check a reliable weather app or your local news.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with a general question\n",
    "response = chat(\"What's the weather like to day?\")\n",
    "print(\"Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat loop (optional)\n",
    "def interactive_chat():\n",
    "    \"\"\"Run an interactive chat session.\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Livestock Advisor Chatbot\")\n",
    "    print(\"Type 'quit' to exit\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    thread_id = f\"interactive_{int(__import__('time').time())}\"\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        response = chat(user_input, thread_id)\n",
    "        print(f\"\\nAssistant: {response}\")\n",
    "\n",
    "# Uncomment to run interactive chat\n",
    "# interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "char_lg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
